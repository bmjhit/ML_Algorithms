{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "\n",
    "#分词以及去除停用词\n",
    "def segmentor(source_file, stopwordslist):\n",
    "    content = []\n",
    "    stop_words = {}.fromkeys([line.rstrip() for line in (open(stopwordslist, encoding='utf8'))])\n",
    "    stop_words = set(stop_words)\n",
    "    data = pd.read_csv(source_file, encoding='utf8', sep='\\t')\n",
    "    text = data['text']\n",
    "    label = data['label']\n",
    "    for row in text:\n",
    "        word_list = jieba.lcut(row)\n",
    "        words = [word for word in word_list if word not in stop_words]\n",
    "        sentence = ' '.join(words)\n",
    "        content.append(sentence)\n",
    "    return label, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# 先转换为词频矩阵形式，再转化为tfidf矩阵，最后转化为DMatrix形式\n",
    "\n",
    "def convert2DMatrix(label, content):\n",
    "    content = pd.DataFrame(content, columns=['text'])\n",
    "    data = pd.concat([label, content], axis=1)\n",
    "    c2n = lambda x : int(x)\n",
    "    data['label'] = data['label'].apply(c2n)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data['text'], data['label'], test_size=0.1)\n",
    "    vectorizer = CountVectorizer(max_features=5000)\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    tfidf = tfidf_transformer.fit_transform(vectorizer.fit_transform(x_train))\n",
    "    x_train_weight = tfidf.to_array()\n",
    "    tfidf = tfidf_transformer.transform(vectorizer.transform(x_test))\n",
    "    x_test_weight = tfidf.to_array()\n",
    "    dtrain = xgb.DMatrix(x_train_weight, label=y_train)\n",
    "    dtest = xgb.DMatrix(x_test_weight, label=y_test)\n",
    "    return dtrain, dtest\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "    #xgboost进行分类\n",
    "def xgboostClassifier(dtrain, dtest):\n",
    "    # xgboost模型构建\n",
    "    # 返回分类类别\n",
    "    param = {'silent': 0, 'eta': 0.3, 'max_depth': 6, 'objective': 'multi:softmax', 'num_class': 3, 'eval_metric': 'merror'}  # 参数\n",
    "    # 返回各类别概率\n",
    "    param = {'silent': 0, 'eta': 0.3, 'max_depth': 6, 'objective': 'multi:softprob', 'num_class': 3, 'eval_metric': 'merror'}  # 参数\n",
    "    evallist = [(dtrain, 'train'), (dtest, 'test')]\n",
    "    num_round = 100  # 循环次数\n",
    "    xgb_model = xgb.train(param, dtrain, num_round,evallist)\n",
    "    # 保存训练模型\n",
    "    # xgb_model.save_model('data/xgb_model')\n",
    "    # xgb_model=xgb.Booster(model_file='data/xgb_model') #加载训练好的xgboost模型\n",
    "        '''\n",
    "    #利用训练完的模型直接测试\n",
    "    xgb_model = xgb.Booster(model_file='data/xgb_model')  # init model #加载模型\n",
    "    dtest = xgb.DMatrix('data/test.buffer')  #加载数据\n",
    "    xgb_test(dtest,xgb_model)\n",
    "    '''\n",
    " \n",
    "    y_predict = xgb_model.predict(dtest)  # 模型预测\n",
    "    label_all = ['负面', '中性','正面']\n",
    "    confusion_mat = metrics.confusion_matrix(y_test, y_predict)\n",
    "    df = pd.DataFrame(confusion_mat, columns=label_all)\n",
    "    df.index = label_all\n",
    "    print('准确率：', metrics.accuracy_score(y_test, y_predict))\n",
    "    print('confusion_matrix:', df)\n",
    "    print('分类报告:', metrics.classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    train_data = pd.read_csv('data/clean_data_train.csv', sep=',', names=['contents', 'labels']).astype(str)\n",
    "    cw = lambda x: int(x)\n",
    "    train_data['labels']=train_data['labels'].apply(cw)\n",
    " \n",
    "    x_train, x_test, y_train, y_test = train_test_split(train_data['contents'], train_data['labels'], test_size=0.1)\n",
    " \n",
    "    # 将语料转化为词袋向量，根据词袋向量统计TF-IDF\n",
    "    vectorizer = CountVectorizer(max_features=5000)\n",
    "    tf_idf_transformer = TfidfTransformer()\n",
    "    tf_idf = tf_idf_transformer.fit_transform(vectorizer.fit_transform(x_train))\n",
    "    x_train_weight = tf_idf.toarray()  # 训练集TF-IDF权重矩阵\n",
    "    tf_idf = tf_idf_transformer.transform(vectorizer.transform(x_test))\n",
    "    x_test_weight = tf_idf.toarray()  # 测试集TF-IDF权重矩阵"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
